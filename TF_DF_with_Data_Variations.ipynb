{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF DF with Data Variations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjX8UBXpAREUqbqc9fNn0q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthikmswamy/TF_Intro_Notebooks/blob/master/TF_DF_with_Data_Variations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6xrI9mMFGAK"
      },
      "source": [
        "## Installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u1n95o8f1Sz"
      },
      "source": [
        "# !pip install -U augly\n",
        "# !sudo apt-get install python3-magic\n",
        "!pip install tensorflow_decision_forests\n",
        "!pip install wurlitzer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZjEjvCeFJtI"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWIfTG5Mgok3"
      },
      "source": [
        "from time import time\n",
        "\n",
        "import tensorflow_decision_forests as tfdf\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "try:\n",
        "  from wurlitzer import sys_pipes\n",
        "except:\n",
        "  from colabtools.googlelog import CaptureLog as sys_pipes\n",
        "\n",
        "from IPython.core.magic import register_line_magic\n",
        "from IPython.display import Javascript\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av22s03cFNMg"
      },
      "source": [
        "## Data Download and Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "ORMNK-GRvs1N",
        "outputId": "0ed081be-ae25-42a7-f42b-e05ca30b4893"
      },
      "source": [
        "! wget -O bestBuy.csv \"https://raw.githubusercontent.com/SAP-samples/data-attribute-recommendation-postman-tutorial-sample/master/Tutorial_Example_Dataset.csv\"\n",
        "\n",
        "# Load a dataset into a Pandas Dataframe.\n",
        "dataset_df = pd.read_csv(\"./bestBuy.csv\", usecols=['manufacturer', 'price', 'level1_category'])\n",
        "\n",
        "# Display the first 3 examples.\n",
        "dataset_df.head(3)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-20 13:30:43--  https://raw.githubusercontent.com/SAP-samples/data-attribute-recommendation-postman-tutorial-sample/master/Tutorial_Example_Dataset.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9921374 (9.5M) [text/plain]\n",
            "Saving to: ‘bestBuy.csv’\n",
            "\n",
            "bestBuy.csv         100%[===================>]   9.46M  35.0MB/s    in 0.3s    \n",
            "\n",
            "2021-07-20 13:30:43 (35.0 MB/s) - ‘bestBuy.csv’ saved [9921374/9921374]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>manufacturer</th>\n",
              "      <th>price</th>\n",
              "      <th>level1_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Duracell</td>\n",
              "      <td>5.49</td>\n",
              "      <td>Connected Home &amp; Housewares</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Duracell</td>\n",
              "      <td>5.49</td>\n",
              "      <td>Connected Home &amp; Housewares</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Duracell</td>\n",
              "      <td>7.49</td>\n",
              "      <td>Connected Home &amp; Housewares</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  manufacturer  price              level1_category\n",
              "0     Duracell   5.49  Connected Home & Housewares\n",
              "1     Duracell   5.49  Connected Home & Housewares\n",
              "2     Duracell   7.49  Connected Home & Housewares"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueBkfGBICQlA",
        "outputId": "e4ced1ad-66e8-4284-e4f7-871dce18b5a2"
      },
      "source": [
        "dataset_df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48087 entries, 0 to 48086\n",
            "Data columns (total 3 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   manufacturer     48023 non-null  object \n",
            " 1   price            48087 non-null  float64\n",
            " 2   level1_category  47906 non-null  object \n",
            "dtypes: float64(1), object(2)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AckVwakyK2w",
        "outputId": "8152b6b5-aef7-4db7-e3b1-56ce8beae776"
      },
      "source": [
        "# Name of the label column.\n",
        "label = \"level1_category\"\n",
        "\n",
        "classes = dataset_df[label].unique().tolist()\n",
        "print(f\"Label classes: {classes}\")\n",
        "\n",
        "dataset_df[label] = dataset_df[label].map(classes.index)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label classes: ['Connected Home & Housewares', nan, 'Car Electronics & GPS', 'Musical Instruments', 'Toys, Games & Drones', 'Video Games', 'Cameras & Camcorders', 'Computers & Tablets', 'Appliances', 'Audio', 'TV & Home Theater', 'Health, Fitness & Beauty', 'Name Brands', 'Cell Phones', 'Movies & Music', 'Magnolia Home Theater', 'Geek Squad', 'Best Buy Gift Cards', 'Wearable Technology', 'Gift Ideas', 'Housewares']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csVpYLqVFSbI"
      },
      "source": [
        "## Helper Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0guQ8ZfPyUGp"
      },
      "source": [
        "# Split the dataset into a training and a testing dataset.\n",
        "# Test split remains a constant \n",
        "def split_dataset(dataset, num_train=10000):\n",
        "  \"\"\"Splits a panda dataframe in two.\"\"\"\n",
        "  dataset = dataset.sample(frac=1.0, random_state=1729)\n",
        "  \n",
        "  test_dataset = dataset[40000:]\n",
        "  train_dataset = dataset[:num_train]\n",
        "  \n",
        "  return train_dataset, test_dataset"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhY2Dcoopv6V"
      },
      "source": [
        "def train_rf_model_with_dataframes(train_df, test_df, label):\n",
        "    train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=label)\n",
        "    test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_df, label=label)\n",
        "\n",
        "    # Specify the model.\n",
        "    model_1 = tfdf.keras.RandomForestModel(num_trees=30)\n",
        "\n",
        "    # Optionally, add evaluation metrics.\n",
        "    model_1.compile(metrics=[\"accuracy\"])\n",
        "\n",
        "    t1 = time()\n",
        "    # Train the model.\n",
        "    with sys_pipes():\n",
        "        model_1.fit(x=train_ds)\n",
        "\n",
        "    evaluation = model_1.evaluate(test_ds)\n",
        "\n",
        "    # print(f\"Loss: {evaluation[0]}\")\n",
        "    print(f\"Accuracy: {evaluation[1]} in {time() - t1} secs\")\n",
        "    return evaluation[1], time() - t1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KWdeFTmwXlu"
      },
      "source": [
        "def train_gbdt_model_with_dataframes(train_df, test_df, label):\n",
        "    train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=label)\n",
        "    test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_df, label=label)\n",
        "\n",
        "    # Specify the model.\n",
        "    model_1 = tfdf.keras.GradientBoostedTreesModel(num_trees=30)\n",
        "\n",
        "    # Optionally, add evaluation metrics.\n",
        "    model_1.compile(metrics=[\"accuracy\"])\n",
        "\n",
        "    t1 = time()\n",
        "    # Train the model.\n",
        "    with sys_pipes():\n",
        "        model_1.fit(x=train_ds)\n",
        "\n",
        "    evaluation = model_1.evaluate(test_ds)\n",
        "\n",
        "    # print(f\"Loss: {evaluation[0]}\")\n",
        "    print(f\"Accuracy: {evaluation[1]} in {time() - t1} secs\")\n",
        "    return evaluation[1], time() - t1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPDKs0dWMEKU"
      },
      "source": [
        "def train_cart_model_with_dataframes(train_df, test_df, label):\n",
        "    train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=label)\n",
        "    test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_df, label=label)\n",
        "\n",
        "    # Specify the model.\n",
        "    model_1 = tfdf.keras.CartModel()\n",
        "\n",
        "    # Optionally, add evaluation metrics.\n",
        "    model_1.compile(metrics=[\"accuracy\"])\n",
        "\n",
        "    t1 = time()\n",
        "    # Train the model.\n",
        "    with sys_pipes():\n",
        "        model_1.fit(x=train_ds)\n",
        "\n",
        "    evaluation = model_1.evaluate(test_ds)\n",
        "\n",
        "    # print(f\"Loss: {evaluation[0]}\")\n",
        "    print(f\"Accuracy: {evaluation[1]} in {time() - t1} secs\")\n",
        "    return evaluation[1], time() - t1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHQjlNHKFayw"
      },
      "source": [
        "## Train with Different Records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDiNb6QjF30m"
      },
      "source": [
        "def train_and_evaluate_on_data(num_train, results_rf, results_gb, results_cm):\n",
        "    train_ds_pd, test_ds_pd = split_dataset(dataset_df, num_train)\n",
        "    print(f\"{len(train_ds_pd)} examples in training, {len(test_ds_pd)} examples for testing.\")\n",
        "\n",
        "    accuracy, time_taken = train_rf_model_with_dataframes(train_ds_pd, test_ds_pd, label)\n",
        "    results_rf.append([num_train, accuracy, time_taken])\n",
        "\n",
        "    accuracy, time_taken = train_gbdt_model_with_dataframes(train_ds_pd, test_ds_pd, label)\n",
        "    results_gb.append([num_train, accuracy, time_taken])\n",
        "\n",
        "    accuracy, time_taken = train_cart_model_with_dataframes(train_ds_pd, test_ds_pd, label)\n",
        "    results_cm.append([num_train, accuracy, time_taken])\n",
        "\n",
        "    return results_rf, results_gb, results_cm"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSg1c2rUWv2_",
        "outputId": "54a7c642-2ef2-49f7-ff26-9c3f55bceb62"
      },
      "source": [
        "results_rf, results_gb, results_cm = [], [], []\n",
        "num_train_list = [500, 1000, 2000, 4000, 8000, 16000, 32000, 40000]\n",
        "for num_train in num_train_list:\n",
        "    results_rf, results_gb, results_cm = train_and_evaluate_on_data(num_train, results_rf, results_gb, results_cm)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500 examples in training, 8087 examples for testing.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-20 13:30:49.287148: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2021-07-20 13:30:49.290940: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2299995000 Hz\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 5s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 8\n",
            "[INFO kernel.cc:393] Number of examples: 500\n",
            "[INFO data_spec_inference.cc:289] 287 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (15 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 500\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:1 (0.2%) has-dict vocab-size:16 num-oods:287 (57.515%) most-frequent:\"<OOD>\" 287 (57.515%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:253.683 min:1.49 max:12300 sd:711.486\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 500 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:0) done accuracy:0.263736 logloss:26.5376\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:13) done accuracy:0.280242 logloss:21.9009\n",
            "[INFO random_forest.cc:578] Training of tree  21/30 (tree index:18) done accuracy:0.270541 logloss:18.4027\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:29) done accuracy:0.288 logloss:16.6408\n",
            "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.288 logloss:16.6408\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpg9lbypms\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 2926 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"RandomForestGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.2808\n",
            "Accuracy: 0.2808210849761963 in 8.342710018157959 secs\n",
            "8/8 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 8\n",
            "[INFO kernel.cc:393] Number of examples: 500\n",
            "[INFO data_spec_inference.cc:289] 287 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (15 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 500\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:1 (0.2%) has-dict vocab-size:16 num-oods:287 (57.515%) most-frequent:\"<OOD>\" 287 (57.515%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:253.683 min:1.49 max:12300 sd:711.486\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1688] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1701] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1710] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1722] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:499] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
            "[INFO gradient_boosted_trees.cc:1075] Training gradient boosted tree on 500 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:1 train-loss:2.504685 train-accuracy:0.429515 valid-loss:2.532742 valid-accuracy:0.391304\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:2 train-loss:2.319265 train-accuracy:0.436123 valid-loss:2.386813 valid-accuracy:0.456522\n",
            "[INFO gradient_boosted_trees.cc:2746] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.97548\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 380 tree(s) i.e. 20  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:20 valid-loss:1.975476 valid-accuracy:0.391304\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpmmgidanu\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 380 root(s), 11376 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - accuracy: 0.3152\n",
            "Accuracy: 0.315197229385376 in 1.3797359466552734 secs\n",
            "8/8 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 8\n",
            "[INFO kernel.cc:393] Number of examples: 500\n",
            "[INFO data_spec_inference.cc:289] 287 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (15 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 500\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:1 (0.2%) has-dict vocab-size:16 num-oods:287 (57.515%) most-frequent:\"<OOD>\" 287 (57.515%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:253.683 min:1.49 max:12300 sd:711.486\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 500 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:366] 101 nodes before pruning. 3 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpbh6p4tey\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 3 node(s), and 1 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.2383\n",
            "Accuracy: 0.2382836639881134 in 0.6427614688873291 secs\n",
            "1000 examples in training, 8087 examples for testing.\n",
            "16/16 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 16\n",
            "[INFO kernel.cc:393] Number of examples: 1000\n",
            "[INFO data_spec_inference.cc:289] 449 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (36 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 1000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:1 (0.1%) has-dict vocab-size:37 num-oods:449 (44.9449%) most-frequent:\"<OOD>\" 449 (44.9449%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:262.11 min:1.49 max:12300 sd:660.015\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 1000 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:2) done accuracy:0.324251 logloss:24.3565\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:9) done accuracy:0.341734 logloss:18.6754\n",
            "[INFO random_forest.cc:578] Training of tree  21/30 (tree index:20) done accuracy:0.347 logloss:15.7316\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:29) done accuracy:0.356 logloss:14.1981\n",
            "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.356 logloss:14.1981\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp062b9hhj\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 4966 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3773\n",
            "Accuracy: 0.3772721588611603 in 0.8515772819519043 secs\n",
            "16/16 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 16\n",
            "[INFO kernel.cc:393] Number of examples: 1000\n",
            "[INFO data_spec_inference.cc:289] 449 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (36 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 1000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:1 (0.1%) has-dict vocab-size:37 num-oods:449 (44.9449%) most-frequent:\"<OOD>\" 449 (44.9449%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:262.11 min:1.49 max:12300 sd:660.015\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1688] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1701] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1710] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1722] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:499] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
            "[INFO gradient_boosted_trees.cc:1075] Training gradient boosted tree on 1000 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:1 train-loss:2.430901 train-accuracy:0.460455 valid-loss:2.428566 valid-accuracy:0.350649\n",
            "[INFO gradient_boosted_trees.cc:2746] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.75173\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 532 tree(s) i.e. 28  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:28 valid-loss:1.751727 valid-accuracy:0.415584\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpfg1c2sag\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 532 root(s), 19408 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f209c7e9dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f209c7e9dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0000e+00 - accuracy: 0.3874\n",
            "Accuracy: 0.387411892414093 in 1.8938877582550049 secs\n",
            "16/16 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 16\n",
            "[INFO kernel.cc:393] Number of examples: 1000\n",
            "[INFO data_spec_inference.cc:289] 449 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (36 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 1000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:1 (0.1%) has-dict vocab-size:37 num-oods:449 (44.9449%) most-frequent:\"<OOD>\" 449 (44.9449%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:262.11 min:1.49 max:12300 sd:660.015\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 1000 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:366] 167 nodes before pruning. 43 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp5c989ik5\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 43 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f209c967200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f209c967200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3054\n",
            "Accuracy: 0.30542847514152527 in 0.6774287223815918 secs\n",
            "2000 examples in training, 8087 examples for testing.\n",
            "32/32 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 32\n",
            "[INFO kernel.cc:393] Number of examples: 2000\n",
            "[INFO data_spec_inference.cc:289] 614 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (88 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 2000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:3 (0.15%) has-dict vocab-size:89 num-oods:614 (30.7461%) most-frequent:\"<OOD>\" 614 (30.7461%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:253.659 min:0.01 max:12300 sd:640.932\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 2000 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:3) done accuracy:0.404632 logloss:21.4592\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:8) done accuracy:0.479859 logloss:14.7911\n",
            "[INFO random_forest.cc:578] Training of tree  21/30 (tree index:21) done accuracy:0.488 logloss:12.2939\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:29) done accuracy:0.4925 logloss:11.1767\n",
            "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.4925 logloss:11.1767\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp1i_a492q\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 8334 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.4635\n",
            "Accuracy: 0.46345987915992737 in 1.7955348491668701 secs\n",
            "32/32 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 32\n",
            "[INFO kernel.cc:393] Number of examples: 2000\n",
            "[INFO data_spec_inference.cc:289] 614 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (88 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 2000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:3 (0.15%) has-dict vocab-size:89 num-oods:614 (30.7461%) most-frequent:\"<OOD>\" 614 (30.7461%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:253.659 min:0.01 max:12300 sd:640.932\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1688] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1701] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1710] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1722] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:499] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
            "[INFO gradient_boosted_trees.cc:1075] Training gradient boosted tree on 2000 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:1 train-loss:2.292626 train-accuracy:0.531798 valid-loss:2.383888 valid-accuracy:0.460227\n",
            "[INFO gradient_boosted_trees.cc:2746] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.52684\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 513 tree(s) i.e. 27  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:27 valid-loss:1.526842 valid-accuracy:0.505682\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpcc7t83a3\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 513 root(s), 21385 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"GradientBoostedTreesGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0000e+00 - accuracy: 0.4757\n",
            "Accuracy: 0.4757017493247986 in 2.2559468746185303 secs\n",
            "32/32 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 32\n",
            "[INFO kernel.cc:393] Number of examples: 2000\n",
            "[INFO data_spec_inference.cc:289] 614 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (88 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 2000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:3 (0.15%) has-dict vocab-size:89 num-oods:614 (30.7461%) most-frequent:\"<OOD>\" 614 (30.7461%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:253.659 min:0.01 max:12300 sd:640.932\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 2000 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:366] 287 nodes before pruning. 77 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp2ftcoeae\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 77 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.4513\n",
            "Accuracy: 0.4513416588306427 in 0.7589678764343262 secs\n",
            "4000 examples in training, 8087 examples for testing.\n",
            "63/63 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 63\n",
            "[INFO kernel.cc:393] Number of examples: 4000\n",
            "[INFO data_spec_inference.cc:289] 759 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (212 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 4000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:5 (0.125%) has-dict vocab-size:213 num-oods:759 (18.9987%) most-frequent:\"<OOD>\" 759 (18.9987%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:260.872 min:0.01 max:12300 sd:631.2\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 4000 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:2) done accuracy:0.600962 logloss:14.3828\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:10) done accuracy:0.606091 logloss:10.7036\n",
            "[INFO random_forest.cc:578] Training of tree  21/30 (tree index:18) done accuracy:0.61625 logloss:8.95603\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:29) done accuracy:0.618 logloss:8.16299\n",
            "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.618 logloss:8.16299\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpb0bzyd_l\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 14888 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.5918\n",
            "Accuracy: 0.5918140411376953 in 2.4782557487487793 secs\n",
            "63/63 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 63\n",
            "[INFO kernel.cc:393] Number of examples: 4000\n",
            "[INFO data_spec_inference.cc:289] 759 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (212 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 4000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:5 (0.125%) has-dict vocab-size:213 num-oods:759 (18.9987%) most-frequent:\"<OOD>\" 759 (18.9987%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:260.872 min:0.01 max:12300 sd:631.2\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1688] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1701] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1710] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1722] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:499] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
            "[INFO gradient_boosted_trees.cc:1075] Training gradient boosted tree on 4000 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:1 train-loss:2.058783 train-accuracy:0.648425 valid-loss:2.124822 valid-accuracy:0.599476\n",
            "[INFO gradient_boosted_trees.cc:2746] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.14679\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 532 tree(s) i.e. 28  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:28 valid-loss:1.146789 valid-accuracy:0.615183\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpgwls29bs\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 532 root(s), 24166 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0000e+00 - accuracy: 0.5995\n",
            "Accuracy: 0.5994806289672852 in 3.07039213180542 secs\n",
            "63/63 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 63\n",
            "[INFO kernel.cc:393] Number of examples: 4000\n",
            "[INFO data_spec_inference.cc:289] 759 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (212 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 4000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:5 (0.125%) has-dict vocab-size:213 num-oods:759 (18.9987%) most-frequent:\"<OOD>\" 759 (18.9987%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:260.872 min:0.01 max:12300 sd:631.2\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 4000 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:366] 497 nodes before pruning. 119 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp51i7vnlt\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 119 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.5731\n",
            "Accuracy: 0.5731420516967773 in 0.8729896545410156 secs\n",
            "8000 examples in training, 8087 examples for testing.\n",
            "125/125 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 125\n",
            "[INFO kernel.cc:393] Number of examples: 8000\n",
            "[INFO data_spec_inference.cc:289] 906 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (381 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 8000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:8 (0.1%) has-dict vocab-size:382 num-oods:906 (11.3363%) most-frequent:\"<OOD>\" 906 (11.3363%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:256.176 min:0.01 max:12300 sd:586.041\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 8000 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:4) done accuracy:0.633803 logloss:13.1991\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:10) done accuracy:0.659781 logloss:8.66796\n",
            "[INFO random_forest.cc:578] Training of tree  21/30 (tree index:20) done accuracy:0.681375 logloss:7.00761\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:29) done accuracy:0.69225 logloss:6.26266\n",
            "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.69225 logloss:6.26266\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpr02z3u9l\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 36334 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"RandomForestGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6872\n",
            "Accuracy: 0.6871522068977356 in 23.577579259872437 secs\n",
            "125/125 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 125\n",
            "[INFO kernel.cc:393] Number of examples: 8000\n",
            "[INFO data_spec_inference.cc:289] 906 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (381 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 8000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:8 (0.1%) has-dict vocab-size:382 num-oods:906 (11.3363%) most-frequent:\"<OOD>\" 906 (11.3363%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:256.176 min:0.01 max:12300 sd:586.041\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1688] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1701] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1710] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1722] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:499] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
            "[INFO gradient_boosted_trees.cc:1075] Training gradient boosted tree on 8000 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:1 train-loss:2.420986 train-accuracy:0.519823 valid-loss:2.477244 valid-accuracy:0.449109\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:2 train-loss:2.110891 train-accuracy:0.606737 valid-loss:2.192795 valid-accuracy:0.557252\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:9 train-loss:1.313544 train-accuracy:0.718464 valid-loss:1.471560 valid-accuracy:0.646310\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:16 train-loss:1.006907 train-accuracy:0.751178 valid-loss:1.198588 valid-accuracy:0.687023\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:23 train-loss:0.850335 train-accuracy:0.763654 valid-loss:1.066212 valid-accuracy:0.685751\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:30 train-loss:0.758309 train-accuracy:0.773773 valid-loss:0.997799 valid-accuracy:0.697201\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 570 tree(s) i.e. 30  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:30 valid-loss:0.997799 valid-accuracy:0.697201\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpwfi9iyx4\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 570 root(s), 32860 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"GradientBoostedTreesGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0000e+00 - accuracy: 0.6937\n",
            "Accuracy: 0.6937059760093689 in 131.69450116157532 secs\n",
            "125/125 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 125\n",
            "[INFO kernel.cc:393] Number of examples: 8000\n",
            "[INFO data_spec_inference.cc:289] 906 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (381 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 8000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:8 (0.1%) has-dict vocab-size:382 num-oods:906 (11.3363%) most-frequent:\"<OOD>\" 906 (11.3363%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:256.176 min:0.01 max:12300 sd:586.041\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 8000 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:366] 1235 nodes before pruning. 391 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmphk_3knjh\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 391 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6115\n",
            "Accuracy: 0.6114752292633057 in 1.8574111461639404 secs\n",
            "16000 examples in training, 8087 examples for testing.\n",
            "250/250 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 250\n",
            "[INFO kernel.cc:393] Number of examples: 16000\n",
            "[INFO data_spec_inference.cc:289] 1024 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (626 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 16000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:18 (0.1125%) has-dict vocab-size:627 num-oods:1024 (6.40721%) most-frequent:\"<OOD>\" 1024 (6.40721%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:21 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:255.794 min:0.01 max:18000 sd:590.45\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 16000 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:1) done accuracy:0.692846 logloss:11.0709\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:10) done accuracy:0.725454 logloss:6.67471\n",
            "[INFO random_forest.cc:578] Training of tree  19/30 (tree index:18) done accuracy:0.749563 logloss:5.46844\n",
            "[INFO random_forest.cc:578] Training of tree  28/30 (tree index:27) done accuracy:0.7575 logloss:4.81412\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:29) done accuracy:0.759313 logloss:4.72709\n",
            "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.759313 logloss:4.72709\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpz1t1_ix4\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 67100 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"RandomForestGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.7564\n",
            "Accuracy: 0.7563991546630859 in 82.80359506607056 secs\n",
            "250/250 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 250\n",
            "[INFO kernel.cc:393] Number of examples: 16000\n",
            "[INFO data_spec_inference.cc:289] 1024 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (626 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 16000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:18 (0.1125%) has-dict vocab-size:627 num-oods:1024 (6.40721%) most-frequent:\"<OOD>\" 1024 (6.40721%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:21 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:255.794 min:0.01 max:18000 sd:590.45\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1688] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1701] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1710] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1722] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:499] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
            "[INFO gradient_boosted_trees.cc:1075] Training gradient boosted tree on 16000 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:1 train-loss:2.467717 train-accuracy:0.502079 valid-loss:2.483016 valid-accuracy:0.488535\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:2 train-loss:2.201852 train-accuracy:0.578517 valid-loss:2.231717 valid-accuracy:0.557325\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:6 train-loss:1.590960 train-accuracy:0.686417 valid-loss:1.660925 valid-accuracy:0.659236\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:10 train-loss:1.267854 train-accuracy:0.735204 valid-loss:1.360176 valid-accuracy:0.697452\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:14 train-loss:1.072730 train-accuracy:0.764033 valid-loss:1.182369 valid-accuracy:0.716560\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:18 train-loss:0.935425 train-accuracy:0.783299 valid-loss:1.058977 valid-accuracy:0.731847\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:22 train-loss:0.843958 train-accuracy:0.794248 valid-loss:0.980143 valid-accuracy:0.748408\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:26 train-loss:0.774142 train-accuracy:0.802010 valid-loss:0.918219 valid-accuracy:0.759873\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:30 train-loss:0.717929 train-accuracy:0.808177 valid-loss:0.873268 valid-accuracy:0.761146\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 600 tree(s) i.e. 30  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:30 valid-loss:0.873268 valid-accuracy:0.761146\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpzvs716wq\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 600 root(s), 35322 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"GradientBoostedTreesGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0000e+00 - accuracy: 0.7581\n",
            "Accuracy: 0.7581303119659424 in 263.0507712364197 secs\n",
            "250/250 [==============================] - 0s 953us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 250\n",
            "[INFO kernel.cc:393] Number of examples: 16000\n",
            "[INFO data_spec_inference.cc:289] 1024 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (626 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 16000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:18 (0.1125%) has-dict vocab-size:627 num-oods:1024 (6.40721%) most-frequent:\"<OOD>\" 1024 (6.40721%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:21 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:255.794 min:0.01 max:18000 sd:590.45\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 16000 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:366] 2263 nodes before pruning. 675 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmphbw_fx5h\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 675 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"RandomForestGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6724\n",
            "Accuracy: 0.6724372506141663 in 2.787523031234741 secs\n",
            "32000 examples in training, 8087 examples for testing.\n",
            "500/500 [==============================] - 1s 999us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 500\n",
            "[INFO kernel.cc:393] Number of examples: 32000\n",
            "[INFO data_spec_inference.cc:289] 1144 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (931 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 32000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:44 (0.1375%) has-dict vocab-size:932 num-oods:1144 (3.57992%) most-frequent:\"<OOD>\" 1144 (3.57992%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:21 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:253.956 min:0.01 max:18000 sd:575.973\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 32000 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:4) done accuracy:0.764318 logloss:8.49483\n",
            "[INFO random_forest.cc:578] Training of tree  7/30 (tree index:10) done accuracy:0.777803 logloss:6.06134\n",
            "[INFO random_forest.cc:578] Training of tree  13/30 (tree index:13) done accuracy:0.797462 logloss:4.78001\n",
            "[INFO random_forest.cc:578] Training of tree  19/30 (tree index:18) done accuracy:0.807171 logloss:4.1572\n",
            "[INFO random_forest.cc:578] Training of tree  25/30 (tree index:24) done accuracy:0.811113 logloss:3.80479\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:29) done accuracy:0.813994 logloss:3.5884\n",
            "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.813994 logloss:3.5884\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpvepa8cjh\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 112638 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"RandomForestGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.8149\n",
            "Accuracy: 0.8148881196975708 in 82.7915563583374 secs\n",
            "500/500 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 500\n",
            "[INFO kernel.cc:393] Number of examples: 32000\n",
            "[INFO data_spec_inference.cc:289] 1144 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (931 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 32000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:44 (0.1375%) has-dict vocab-size:932 num-oods:1144 (3.57992%) most-frequent:\"<OOD>\" 1144 (3.57992%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:21 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:253.956 min:0.01 max:18000 sd:575.973\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1688] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1701] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1710] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1722] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:499] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
            "[INFO gradient_boosted_trees.cc:1075] Training gradient boosted tree on 32000 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:1 train-loss:2.441828 train-accuracy:0.516566 valid-loss:2.453953 valid-accuracy:0.502362\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:2 train-loss:2.211591 train-accuracy:0.578317 valid-loss:2.230616 valid-accuracy:0.544882\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:5 train-loss:1.729643 train-accuracy:0.666297 valid-loss:1.772863 valid-accuracy:0.635591\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:8 train-loss:1.438660 train-accuracy:0.708517 valid-loss:1.496117 valid-accuracy:0.674016\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:11 train-loss:1.238807 train-accuracy:0.737693 valid-loss:1.307113 valid-accuracy:0.697008\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:14 train-loss:1.088870 train-accuracy:0.763053 valid-loss:1.165866 valid-accuracy:0.727559\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:17 train-loss:0.987956 train-accuracy:0.777381 valid-loss:1.071286 valid-accuracy:0.742992\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:20 train-loss:0.904093 train-accuracy:0.791327 valid-loss:0.993378 valid-accuracy:0.757795\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:23 train-loss:0.836633 train-accuracy:0.803677 valid-loss:0.929567 valid-accuracy:0.765669\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:26 train-loss:0.783156 train-accuracy:0.811830 valid-loss:0.881306 valid-accuracy:0.773543\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:29 train-loss:0.736151 train-accuracy:0.819566 valid-loss:0.838564 valid-accuracy:0.782992\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:30 train-loss:0.722443 train-accuracy:0.821752 valid-loss:0.826466 valid-accuracy:0.782992\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 600 tree(s) i.e. 30  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:30 valid-loss:0.826466 valid-accuracy:0.782992\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpz_qye8mt\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 600 root(s), 35946 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"GradientBoostedTreesGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0000e+00 - accuracy: 0.7893\n",
            "Accuracy: 0.7892914414405823 in 370.16597843170166 secs\n",
            "500/500 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 500\n",
            "[INFO kernel.cc:393] Number of examples: 32000\n",
            "[INFO data_spec_inference.cc:289] 1144 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (931 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 32000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:44 (0.1375%) has-dict vocab-size:932 num-oods:1144 (3.57992%) most-frequent:\"<OOD>\" 1144 (3.57992%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:21 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:253.956 min:0.01 max:18000 sd:575.973\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 32000 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:366] 3871 nodes before pruning. 1225 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmprvjzlvtp\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 1225 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.7515\n",
            "Accuracy: 0.7514529228210449 in 5.532477140426636 secs\n",
            "40000 examples in training, 8087 examples for testing.\n",
            "625/625 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 625\n",
            "[INFO kernel.cc:393] Number of examples: 40000\n",
            "[INFO data_spec_inference.cc:289] 1153 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (1045 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 40000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:52 (0.13%) has-dict vocab-size:1046 num-oods:1153 (2.88625%) most-frequent:\"<OOD>\" 1153 (2.88625%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:22 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:255.547 min:0.01 max:28000 sd:588.007\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 40000 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:0) done accuracy:0.778377 logloss:7.98809\n",
            "[INFO random_forest.cc:578] Training of tree  7/30 (tree index:6) done accuracy:0.794312 logloss:5.52983\n",
            "[INFO random_forest.cc:578] Training of tree  13/30 (tree index:13) done accuracy:0.812481 logloss:4.32219\n",
            "[INFO random_forest.cc:578] Training of tree  19/30 (tree index:19) done accuracy:0.822135 logloss:3.7724\n",
            "[INFO random_forest.cc:578] Training of tree  25/30 (tree index:24) done accuracy:0.826721 logloss:3.44836\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:29) done accuracy:0.828875 logloss:3.23323\n",
            "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.828875 logloss:3.23323\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp946ibqun\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 131136 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"RandomForestGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.8313\n",
            "Accuracy: 0.8313342332839966 in 142.542662858963 secs\n",
            "625/625 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 625\n",
            "[INFO kernel.cc:393] Number of examples: 40000\n",
            "[INFO data_spec_inference.cc:289] 1153 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (1045 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 40000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:52 (0.13%) has-dict vocab-size:1046 num-oods:1153 (2.88625%) most-frequent:\"<OOD>\" 1153 (2.88625%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:22 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:255.547 min:0.01 max:28000 sd:588.007\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1688] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1701] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1710] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1722] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:499] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
            "[INFO gradient_boosted_trees.cc:1075] Training gradient boosted tree on 40000 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:1 train-loss:2.458010 train-accuracy:0.529781 valid-loss:2.459713 valid-accuracy:0.509572\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:2 train-loss:2.190670 train-accuracy:0.593922 valid-loss:2.201176 valid-accuracy:0.574559\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:5 train-loss:1.709499 train-accuracy:0.675687 valid-loss:1.730257 valid-accuracy:0.653904\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:8 train-loss:1.420376 train-accuracy:0.718540 valid-loss:1.452650 valid-accuracy:0.697229\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:11 train-loss:1.222638 train-accuracy:0.745379 valid-loss:1.263874 valid-accuracy:0.725693\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:14 train-loss:1.075657 train-accuracy:0.768498 valid-loss:1.127880 valid-accuracy:0.744081\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:17 train-loss:0.970285 train-accuracy:0.785235 valid-loss:1.029183 valid-accuracy:0.762469\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:20 train-loss:0.888751 train-accuracy:0.798834 valid-loss:0.954554 valid-accuracy:0.772544\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:23 train-loss:0.821590 train-accuracy:0.808770 valid-loss:0.891976 valid-accuracy:0.781864\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:26 train-loss:0.768245 train-accuracy:0.817374 valid-loss:0.842659 valid-accuracy:0.790428\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:29 train-loss:0.722492 train-accuracy:0.824757 valid-loss:0.800832 valid-accuracy:0.798237\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:30 train-loss:0.708173 train-accuracy:0.827089 valid-loss:0.787731 valid-accuracy:0.800504\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 630 tree(s) i.e. 30  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:30 valid-loss:0.787731 valid-accuracy:0.800504\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpkr0webmn\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 630 root(s), 37648 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"GradientBoostedTreesGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0000e+00 - accuracy: 0.8002\n",
            "Accuracy: 0.8001731038093567 in 443.1349506378174 secs\n",
            "625/625 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 625\n",
            "[INFO kernel.cc:393] Number of examples: 40000\n",
            "[INFO data_spec_inference.cc:289] 1153 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (1045 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 40000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:52 (0.13%) has-dict vocab-size:1046 num-oods:1153 (2.88625%) most-frequent:\"<OOD>\" 1153 (2.88625%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:22 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:255.547 min:0.01 max:28000 sd:588.007\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 40000 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:366] 4501 nodes before pruning. 1535 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpa32s8evq\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 1535 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"RandomForestGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.7667\n",
            "Accuracy: 0.7666625380516052 in 4.98656702041626 secs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-XEOe1vFn6Z"
      },
      "source": [
        "## Plotting Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "I6e-QbOzI1oN",
        "outputId": "ad846a9e-be97-435c-dce4-92e437b259d5"
      },
      "source": [
        "x  = [res[0] for res in results_rf]\n",
        "y1 = [res[1] for res in results_rf]\n",
        "y2 = [res[1] for res in results_gb]\n",
        "y3 = [res[1] for res in results_cm]\n",
        "plt.plot(x, y1, label=\"Random Forests\", marker='^')\n",
        "plt.plot(x, y2, label=\"Gradient Boosting\", marker='o')\n",
        "plt.plot(x, y3, label=\"CART\", marker='o')\n",
        "plt.plot()\n",
        "\n",
        "plt.xlabel(\"Number of Records\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Plot of # of Records vs. Accuracies\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "8jIjVRxHJjTt",
        "outputId": "389edc28-441e-4ccf-bfef-fc93eb63adbd"
      },
      "source": [
        "x  = [res[0] for res in results_rf]\n",
        "y1 = [res[2] for res in results_rf]\n",
        "y2 = [res[2] for res in results_gb]\n",
        "y3 = [res[1] for res in results_cm]\n",
        "plt.plot(x, y1, label=\"Random Forests\", marker='^')\n",
        "plt.plot(x, y2, label=\"Gradient Boosting\", marker='o')\n",
        "plt.plot(x, y3, label=\"CART\", marker='o')\n",
        "plt.plot()\n",
        "\n",
        "plt.xlabel(\"Number of Records\")\n",
        "plt.ylabel(\"Time Taken (secs)\")\n",
        "plt.title(\"Plot of # of Records vs. Time Taken to Train\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}